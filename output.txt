=== Archivo: ./app/routers/users.py ===
from fastapi import APIRouter, Depends
from sqlalchemy.orm import Session
from app.database import SessionLocal
from app.schemas import UserCreate, UserResponse
from app.crud import create_user, get_user

router = APIRouter(prefix="/users", tags=["Users"])

def get_db():
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()

@router.post("/", response_model=UserResponse)
def create_new_user(user: UserCreate, db: Session = Depends(get_db)):
    return create_user(db, user)

@router.get("/{user_id}", response_model=UserResponse)
def get_user_by_id(user_id: int, db: Session = Depends(get_db)):
    user = get_user(db, user_id)
    if user is None:
        raise HTTPException(status_code=404, detail="User not found")
    return user


# APIRouter() ‚Üí Agrupa las rutas de usuarios.
# @router.post("/") ‚Üí Endpoint para crear usuarios.
# @router.get("/{user_id}") ‚Üí Endpoint para obtener un usuario por ID.

=== Archivo: ./app/routers/__init__.py ===


=== Archivo: ./app/routers/logs.py ===
from fastapi import APIRouter
from app.mongodb import logs_collection
from app.schemas import LogEntry
from typing import List

router = APIRouter(prefix="/logs", tags=["Logs"])

@router.get("/", response_model=List[LogEntry])
async def get_logs():
    logs = await logs_collection.find().to_list(100)
    return logs



# @router.get("/") ‚Üí Endpoint para obtener los logs.
# logs_collection.find().to_list(100) ‚Üí Recupera hasta 100 registros de MongoDB.

=== Archivo: ./app/routers/ssh.py ===
from fastapi import APIRouter, HTTPException
from app.models.ssh_model import SSHRequest
from services.ssh_client import SSHClient

router = APIRouter()

@router.post("/execute")
def execute_command(request: SSHRequest):
    ssh = SSHClient(request.server_ip, request.username, request.password, request.key_file)

    if not ssh.connect():
        raise HTTPException(status_code=400, detail="‚ùå Error al conectar v√≠a SSH")

    output = ssh.execute_command(request.command)
    ssh.close()

    return {"server": request.server_ip, "output": output}



# @router.post("/execute") ‚Üí Endpoint para recibir y ejecutar comandos.
# SSHRequest ‚Üí Modelo de datos que define los par√°metros requeridos.
# ssh.connect() ‚Üí Establece conexi√≥n SSH con el servidor remoto.
# ssh.execute_command(request.command) ‚Üí Ejecuta el comando enviado.
# return {"server": request.server_ip, "output": output} ‚Üí Devuelve la salida del comando.

=== Archivo: ./app/routers/ansible.py ===
from fastapi import APIRouter, HTTPException
from app.ansible.ansible_runner import run_playbook

router = APIRouter()

@router.post("/run-playbook/{playbook_name}")
def execute_playbook(playbook_name: str):
    playbook_path = f"app/ansible/playbooks/{playbook_name}.yml"
    # inventory_path = f"app/ansible/inventory.yml"  # O .ini seg√∫n el caso
    try:
        output = run_playbook(playbook_path)
        return {"playbook": playbook_name, "output": output}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))



# @router.post("/run-playbook/{playbook_name}") ‚Üí Recibe el nombre del playbook y lo ejecuta.
# run_playbook(playbook_path) ‚Üí Llama a la funci√≥n que ejecuta Ansible.

=== Archivo: ./app/routers/tasks.py ===
from fastapi import APIRouter
from app.tasks import process_data

router = APIRouter()

@router.post("/tasks/")
async def create_task(data: dict):
    """Recibe datos y ejecuta la tarea en segundo plano."""
    task = process_data.apply_async(args=[data])
    return {"task_id": task.id, "status": "Task started"}

@router.get("/tasks/{task_id}")
async def get_task_status(task_id: str):
    """Consulta el estado de una tarea espec√≠fica."""
    from app.cel import celery_app
    task_result = celery_app.AsyncResult(task_id)
    return {"task_id": task_id, "status": task_result.status, "result": task_result.result}


# POST /tasks/ ‚Üí Inicia una tarea en segundo plano.
# GET /tasks/{task_id} ‚Üí Consulta el estado de una tarea en ejecuci√≥n.

=== Archivo: ./app/main.py ===
from fastapi import FastAPI, Request
from app.routers import users, logs, ssh, ansible, tasks
from datetime import datetime
from app.mongodb import logs_collection
from app.schemas import LogEntry
import json

app = FastAPI(title="API con FastAPI, PostgreSQL, Mongo, Streamlit - supportIQ")

@app.middleware("http")
async def log_requests(request: Request, call_next):
    response = await call_next(request)
    
    log_data = LogEntry(
        timestamp=datetime.utcnow(),
        method=request.method,
        path=str(request.url.path),
        status_code=response.status_code,
        client_ip=request.client.host
    ).dict()

    await logs_collection.insert_one(log_data)  # Guardar log en MongoDB
    
    return response


app.include_router(users.router)
app.include_router(logs.router)
app.include_router(ssh.router, prefix="/ssh")
app.include_router(ansible.router)
app.include_router(tasks.router)


@app.get("/")
def root():
    return {"message": "Bienvenido a la API supportIQ"}



# FastAPI(title="API con FastAPI y PostgreSQL") ‚Üí Define la app.
# app.include_router(users.router) ‚Üí Agrega las rutas de usuarios.

# @app.middleware("http") ‚Üí Intercepta cada petici√≥n.
# request.method ‚Üí Captura el m√©todo HTTP.
# request.url.path ‚Üí Obtiene la ruta accedida.
# request.client.host ‚Üí Obtiene la IP del cliente.
# await logs_collection.insert_one(log_data) ‚Üí Guarda el log en MongoDB.

=== Archivo: ./app/config.py ===
import configparser
import os

# Obtener la ruta absoluta del archivo config.ini
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
CONFIG_PATH = os.path.join(BASE_DIR, "../config.ini")

# Cargar configuraci√≥n desde config.ini
config = configparser.ConfigParser()
config.read(CONFIG_PATH)

# Construir la URL de conexi√≥n a PostgreSQL
DB_CONFIG = config["database"]
DATABASE_URL = f"postgresql://{DB_CONFIG['USER']}:{DB_CONFIG['PASSWORD']}@{DB_CONFIG['HOST']}:{DB_CONFIG['PORT']}/{DB_CONFIG['NAME']}"

# Construir la URL de conexi√≥n a MONGP
DB_CONFIG_MONGO = config["databaseMongo"]
MONGODB_URL = f"mongodb://{DB_CONFIG_MONGO['USER']}:{DB_CONFIG_MONGO['PASSWORD']}@{DB_CONFIG_MONGO['HOST']}:{DB_CONFIG_MONGO['PORT']}"
# MONGODB_URL = os.getenv("MONGODB_URL", "mongodb://admin:password@localhost:27017")
MONGO_DB_NAME = "audit_logs"




# configparser.ConfigParser() ‚Üí Carga el archivo .ini.
# config.read(CONFIG_PATH) ‚Üí Lee las propiedades de la secci√≥n [database].
# DATABASE_URL ‚Üí Se genera din√°micamente con los valores del archivo config.ini.

# MONGODB_URL ‚Üí Obtiene la URL de MongoDB.
# MONGO_DB_NAME ‚Üí Nombre de la base de datos de logs.

=== Archivo: ./app/database.py ===
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker, declarative_base
from app.config import DATABASE_URL

# Crear el motor de conexi√≥n
engine = create_engine(DATABASE_URL)

# Crear la sesi√≥n de base de datos
SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)

# Base para modelos ORM
Base = declarative_base()


# create_engine(DATABASE_URL) ‚Üí Crea el motor de PostgreSQL.
# SessionLocal ‚Üí Manejador de sesiones de SQLAlchemy.
# Base ‚Üí Se usar√° para definir modelos ORM.

=== Archivo: ./app/schemas.py ===
from pydantic import BaseModel
from datetime import datetime
from typing import Optional, Dict, Any

class UserBase(BaseModel):
    username: str

class UserCreate(UserBase):
    password: str

class UserResponse(UserBase):
    id: int
    created_at: datetime

    class Config:
        from_attributes = True

# UserBase ‚Üí Define los campos compartidos.
# UserCreate ‚Üí Se usa para recibir datos de creaci√≥n de usuarios.
# UserResponse ‚Üí Se usa para devolver datos en la API.


class LogEntry(BaseModel):
    timestamp: datetime
    method: str
    path: str
    status_code: int
    client_ip: str




# timestamp: datetime ‚Üí Fecha y hora de la petici√≥n.
# method: str ‚Üí M√©todo HTTP (GET, POST, etc.).
# path: str ‚Üí Ruta de la API.
# status_code: int ‚Üí C√≥digo de respuesta HTTP.
# client_ip: str ‚Üí IP del cliente.

=== Archivo: ./app/crud.py ===
from sqlalchemy.orm import Session
from app.models.models import User
# from app.models.user_model import User
from app.schemas import UserCreate

def create_user(db: Session, user: UserCreate):
    new_user = User(username=user.username, password=user.password)
    db.add(new_user)
    db.commit()
    db.refresh(new_user)
    return new_user

def get_user(db: Session, user_id: int):
    return db.query(User).filter(User.id == user_id).first()



# create_user() ‚Üí Inserta un nuevo usuario en la BD.
# get_user() ‚Üí Busca un usuario por ID.

=== Archivo: ./app/mongodb.py ===
from motor.motor_asyncio import AsyncIOMotorClient
from app.config import MONGODB_URL, MONGO_DB_NAME

client = AsyncIOMotorClient(MONGODB_URL)
db = client[MONGO_DB_NAME]
logs_collection = db["logs"]



# AsyncIOMotorClient(MONGODB_URL) ‚Üí Conexi√≥n as√≠ncrona a MongoDB.
# db["logs"] ‚Üí Crea una colecci√≥n logs en la base de datos.

=== Archivo: ./app/models/ssh_model.py ===
from pydantic import BaseModel
from typing import Optional
from sqlalchemy import Column, Integer, String
from app.database import Base  # Aseg√∫rate de que 'Base' est√© correctamente importado


class SSHRequest(BaseModel):
    server_ip: str
    username: str
    password: Optional[str] = None
    key_file: Optional[str] = None
    command: str

# BaseModel ‚Üí Valida los datos de entrada.
# Optional[str] ‚Üí Permite que password y key_file sean opcionales.



class SSHModel(Base):
    __tablename__ = "ssh_connections"

    id = Column(Integer, primary_key=True, index=True)
    host = Column(String, nullable=False)
    user = Column(String, nullable=False)
    password = Column(String, nullable=False)  # ‚ö†Ô∏è No se recomienda guardar contrase√±as en texto plano

=== Archivo: ./app/models/__init__.py ===
from .ssh_model import SSHModel  # Importa otros modelos aqu√≠ si existen
from .user_model import User  # Agrega el modelo de usuario correctamente

__all__ = ["SSHModel", "User"]


=== Archivo: ./app/models/user_model.py ===
from sqlalchemy import Column, Integer, String
from app.database import Base

class User(Base):
    __tablename__ = "users"

    id = Column(Integer, primary_key=True, index=True)
    username = Column(String, unique=True, index=True)
    password = Column(String)  # üîπ ¬°Recuerda cifrar la contrase√±a!


=== Archivo: ./app/models/models.py ===
from sqlalchemy import Column, Integer, String, TIMESTAMP
from sqlalchemy.sql import func
from app.database import Base

class User(Base):
    __tablename__ = "users"
    __table_args__ = {"schema": "app"}  # <--- Definir el esquema aqu√≠

    id = Column(Integer, primary_key=True, index=True)
    username = Column(String(50), unique=True, nullable=False)
    password = Column(String, nullable=False)
    created_at = Column(TIMESTAMP, server_default=func.now())


# __tablename__ = "users" ‚Üí Define la tabla en PostgreSQL.
# Column(Integer, primary_key=True, index=True) ‚Üí Clave primaria.
# Column(String(50), unique=True, nullable=False) ‚Üí Nombre de usuario √∫nico.
# Column(TIMESTAMP, server_default=func.now()) ‚Üí Marca de tiempo autom√°tica.

=== Archivo: ./app/ansible/inventory.yml ===
all:
  hosts:
    server1:
      ansible_host: 10.71.70.55
      ansible_user: spatino
      ansible_ssh_private_key_file: ~/.ssh/id_rsa
    # server2:
    #   ansible_host: 192.168.1.11
    #   ansible_user: admin
    #   ansible_ssh_private_key_file: ~/.ssh/id_rsa


=== Archivo: ./app/ansible/ansible_runner.py ===
# import ansible_runner

# def run_playbook(playbook_path):
#     try:
#         result = ansible_runner.run(private_data_dir="app/ansible", playbook=playbook_path)
#         return result.stdout
#     except Exception as e:
#         return str(e)

# ansible_runner.run() ‚Üí Ejecuta un playbook de Ansible.
# private_data_dir="ansible" ‚Üí Define la carpeta donde est√° el inventario.
import subprocess
import os

def run_playbook(playbook_path):
    try:
        ansible_bin = "venv/bin/ansible-playbook"
        inventory_path = f"app/ansible/inventory.yml"  # O .ini seg√∫n el caso
        command = [ansible_bin, "-i", inventory_path, playbook_path]
        
        result = subprocess.run(command, capture_output=True, text=True)
        return result.stdout if result.returncode == 0 else result.stderr
    except Exception as e:
        return str(e)








# import ansible_runner
# import os

# BASE_DIR = os.path.dirname(os.path.abspath(__file__))  # Directorio del script
# ANSIBLE_DIR = os.path.join(BASE_DIR, "..", "ansible")  # Ajusta la ruta

# def run_playbook(playbook_name):
#     playbook_path = os.path.join(ANSIBLE_DIR, "playbooks", f"{playbook_name}.yml")

#     if not os.path.exists(playbook_path):
#         return f"Playbook {playbook_name}.yml no encontrado en {ANSIBLE_DIR}/playbooks"

#     try:
#         result = ansible_runner.run(private_data_dir=ANSIBLE_DIR, playbook=playbook_path)
#         return result.stdout
#     except Exception as e:
#         return str(e)







=== Archivo: ./app/ansible/playbooks/deploy_app.yml ===
---
- name: Recopilar informaci√≥n del sistema
  hosts: all
  gather_facts: no
  tasks:
    - name: Obtener el nombre del kernel
      command: uname -r
      register: kernel_version

    - name: Mostrar la versi√≥n del kernel
      debug:
        msg: "Versi√≥n del kernel: {{ kernel_version.stdout }}"

    - name: Obtener la fecha y hora actual
      command: date
      register: system_date

    - name: Mostrar la fecha y hora
      debug:
        msg: "Fecha y hora actual: {{ system_date.stdout }}"

    - name: Obtener el nombre del host
      command: hostname
      register: host_name

    - name: Mostrar el nombre del host
      debug:
        msg: "Nombre del host: {{ host_name.stdout }}"


=== Archivo: ./app/ansible/playbooks/update_servers.yml ===


=== Archivo: ./app/ansible/__init__.py ===


=== Archivo: ./app/cel.py ===
from celery import Celery

# Configuraci√≥n de Celery con Redis como broker
celery_app = Celery(
    "supportIQ_tasks",
    broker="redis://redis_broker:6379/0",
    backend="redis://redis_broker:6379/0",
    include=["app.tasks"]
)

# Configuraci√≥n opcional para evitar p√©rdida de tareas
celery_app.conf.task_acks_late = True
celery_app.conf.worker_prefetch_multiplier = 1
celery_app.conf.result_expires = 3600  # Expiraci√≥n de resultados en 1 hora



# Celery("supportIQ_tasks") ‚Üí Define la aplicaci√≥n Celery.
# broker="redis://redis_broker:6379/0" ‚Üí Usa Redis como cola de mensajes.
# backend="redis://redis_broker:6379/0" ‚Üí Guarda los resultados en Redis.
# include=["app.tasks"] ‚Üí Importa las tareas desde el archivo tasks.py.

=== Archivo: ./app/tasks.py ===
from time import sleep
from app.cel import celery_app

@celery_app.task(name="process_data_task")
def process_data(data: dict):
    """Simula una tarea de procesamiento pesado."""
    sleep(5)  # Simula un proceso que tarda 5 segundos
    return {"status": "completed", "processed_data": data}



# @celery_app.task ‚Üí Define una tarea que Celery ejecutar√° en segundo plano.
# sleep(5) ‚Üí Simula un proceso largo.
# Retorna el estado "completed" cuando termina.


=== Archivo: ./.env ===


=== Archivo: ./requirements.txt ===
alembic==1.14.1
annotated-types==0.7.0
ansible==11.2.0
ansible-core==2.18.2
ansible-runner==2.4.0
anyio==4.8.0
bcrypt==4.2.1
certifi==2025.1.31
cffi==1.17.1
click==8.1.8
cryptography==44.0.0
decorator==5.1.1
Deprecated==1.2.18
dnspython==2.7.0
email_validator==2.2.0
fabric==3.2.2
fastapi==0.115.8
fastapi-cli==0.0.7
greenlet==3.1.1
h11==0.14.0
httpcore==1.0.7
httptools==0.6.4
httpx==0.28.1
idna==3.10
invoke==2.2.0
itsdangerous==2.2.0
Jinja2==3.1.5
lockfile==0.12.2
Mako==1.3.9
markdown-it-py==3.0.0
MarkupSafe==3.0.2
mdurl==0.1.2
motor==3.7.0
orjson==3.10.15
packaging==24.2
paramiko==3.5.1
pexpect==4.9.0
psycopg2==2.9.10
psycopg2-binary==2.9.10
ptyprocess==0.7.0
pycparser==2.22
pydantic==2.10.6
pydantic-extra-types==2.10.2
pydantic-settings==2.7.1
pydantic_core==2.27.2
Pygments==2.19.1
pymongo==4.11.1
PyNaCl==1.5.0
python-daemon==3.1.2
python-dotenv==1.0.1
python-multipart==0.0.20
PyYAML==6.0.2
resolvelib==1.0.1
rich==13.9.4
rich-toolkit==0.13.2
shellingham==1.5.4
sniffio==1.3.1
SQLAlchemy==2.0.38
starlette==0.45.3
typer==0.15.1
typing_extensions==4.12.2
ujson==5.10.0
uvicorn==0.34.0
uvloop==0.21.0
watchfiles==1.0.4
websockets==14.2
wrapt==1.17.2


=== Archivo: ./docker-compose.yml ===


=== Archivo: ./README.md ===


=== Archivo: ./config.ini ===
[database]
HOST=172.20.0.2
PORT=5432
USER=supportIQ
PASSWORD=supportIQ
NAME=supportIQ

[databaseMongo]
MONGO_DB_NAME = audit_logs
USER=supportIQ
PASSWORD=supportIQ
HOST=172.21.0.2
PORT=27017


=== Archivo: ./services/ssh_client.py ===
import paramiko

class SSHClient:
    def __init__(self, hostname, username, password=None, key_file=None):
        self.hostname = hostname
        self.username = username
        self.password = password
        self.key_file = key_file
        self.client = None

    def connect(self):
        try:
            self.client = paramiko.SSHClient()
            self.client.set_missing_host_key_policy(paramiko.AutoAddPolicy())
            
            if self.key_file:
                self.client.connect(self.hostname, username=self.username, key_filename=self.key_file)
            else:
                self.client.connect(self.hostname, username=self.username, password=self.password)

            return True
        except Exception as e:
            print(f"Error al conectar: {e}")
            return False

    def execute_command(self, command):
        if self.client is None:
            return "‚ùå No conectado"

        stdin, stdout, stderr = self.client.exec_command(command)
        output = stdout.read().decode()
        error = stderr.read().decode()

        return output if output else error

    def close(self):
        if self.client:
            self.client.close()



# paramiko.SSHClient() ‚Üí Crea un cliente SSH.
# set_missing_host_key_policy() ‚Üí Permite conexiones a hosts desconocidos.
# connect() ‚Üí Se conecta usando contrase√±a o clave SSH.
# exec_command() ‚Üí Ejecuta un comando en el servidor remoto.
# close() ‚Üí Cierra la conexi√≥n SSH.

=== Archivo: ./test/test.py ===
from sqlalchemy import create_engine, inspect

DATABASE_URL = "postgresql://supportIQ:supportIQ@172.20.0.2:5432/supportIQ"
engine = create_engine(DATABASE_URL)

inspector = inspect(engine)
print(inspector.get_table_names(schema= "app"))  # Esto imprimir√° todas las tablas en la BD

=== Archivo: ./.gitignore ===
# üöÄ Archivos y carpetas del entorno virtual (evita subir dependencias innecesarias)
venv/
env/
*.pyc
__pycache__/
*.pyo
*.pyd
.Python
pip-log.txt
pip-delete-this-directory.txt

# üîë Variables de entorno y credenciales (asegura que no subas contrase√±as)
.env
*.env

# üì¶ Dependencias y compilaciones (evita subir archivos generados)
node_modules/
dist/
build/
.cache/
*.egg-info/

# üóë Archivos de logs (evita archivos de depuraci√≥n locales)
*.log
logs/
debug.log

# üíª Archivos espec√≠ficos del sistema operativo (ignora archivos generados por Mac y Windows)
.DS_Store
Thumbs.db

# üõ† IDEs y editores (excluye configuraciones de desarrollo local)
.vscode/
.idea/
*.iml
*.sublime-workspace

# üìÑ Archivos de Docker (si usas Docker en el proyecto)
docker-compose.override.yml


=== Archivo: ./output.txt ===


